{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "spark = SparkSession.builder.appName('cluster').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"marketplace\",       StringType(),    True), \\\n",
    "    StructField(\"customer_id\",       StringType(),    True), \\\n",
    "    StructField(\"review_id\",         StringType(),    True), \\\n",
    "    StructField(\"product_id\",        StringType(),    True), \\\n",
    "    StructField(\"product_parent\",    StringType(),    True), \\\n",
    "    StructField(\"product_title\",     StringType(),    True), \\\n",
    "    StructField(\"product_category\",  StringType(),    True), \\\n",
    "    StructField(\"star_rating\",       IntegerType(),   True), \\\n",
    "    StructField(\"helpful_votes\",     IntegerType(),   True), \\\n",
    "    StructField(\"total_votes\",       IntegerType(),   True), \\\n",
    "    StructField(\"vine\",              StringType(),    True), \\\n",
    "    StructField(\"verified_purchase\", StringType(),    True), \\\n",
    "    StructField(\"review_headline\",   StringType(),    True), \\\n",
    "    StructField(\"review_body\",       StringType(),    True), \\\n",
    "    StructField(\"review_date\",       TimestampType(), True), \\\n",
    "  ])\n",
    "\n",
    "path = ['archive/amazon_reviews_us_Apparel_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Automotive_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Baby_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Beauty_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Books_v1_02.tsv',\n",
    "        'archive/amazon_reviews_us_Camera_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Electronics_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Furniture_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Sports_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Grocery_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv',\n",
    "        'archive/amazon_reviews_us_Music_v1_00.tsv']\n",
    "\n",
    "data = spark.read.csv(path, schema=schema, header=True, sep='\\t', mode='DROPMALFORMED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182530"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_category = ['Sports', 'Baby', 'Apparel', 'Grocery', 'Electronics', 'Automotive', 'Books', 'Music', 'Furniture', 'Personal_Care_Appliances', 'Camera', 'Beauty']\n",
    "data_filter = data.filter(data.product_category.isin(product_category))\n",
    "\n",
    "data_filter.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select product info columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------------------------------------------------------------------------+----------------+\n",
      "|product_id|product_parent|product_title                                                              |product_category|\n",
      "+----------+--------------+---------------------------------------------------------------------------+----------------+\n",
      "|B00OZU7BOY|457541908     |Ladies Knee High 3 Pack Fairisle Design Thermal Socks Size 4-7             |Apparel         |\n",
      "|B00OZU73D8|452184423     |Texere Women's Bamboo Yoga Capri Pants (Atalanta) Luxury Workout Clothing  |Apparel         |\n",
      "|B00OZU715I|452184423     |Texere Women's Bamboo Yoga Capri Pants (Atalanta) Luxury Workout Clothing  |Apparel         |\n",
      "|B00OZU6YJC|452184423     |Texere Women's Bamboo Yoga Capri Pants (Atalanta) Luxury Workout Clothing  |Apparel         |\n",
      "|B00OZU6VD6|138895673     |LOCOMO Men Women Winter Warm Corduroy Folding Ear Flap Warmer Cap FFH222BLK|Apparel         |\n",
      "+----------+--------------+---------------------------------------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_info = data_filter.select('product_id', 'product_parent', 'product_title', 'product_category')\n",
    "product_info.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, MinHashLSH, NGram, RegexTokenizer\n",
    "regexTokenizer_title = RegexTokenizer(inputCol='product_title', outputCol=\"token_title\", pattern=\"\\\\W\")\n",
    "tokenized_title = regexTokenizer_title.transform(product_info)\n",
    "\n",
    "regexTokenizer_category = RegexTokenizer(inputCol='product_category', outputCol=\"token_category\", pattern=\"\\\\W\")\n",
    "tokenized_all = regexTokenizer_category.transform(tokenized_title)\n",
    "\n",
    "# tokenized_all.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_title = StopWordsRemover(inputCol='token_title', outputCol='nostop_title')\n",
    "stop_removed_title = remove_stop_title.transform(tokenized_all)\n",
    "\n",
    "remove_stop_cat = StopWordsRemover(inputCol='token_category', outputCol='nostop_cat')\n",
    "stop_removed_all = remove_stop_cat.transform(stop_removed_title)\n",
    "\n",
    "# stop_removed_all.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split words into characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_title = stop_removed_all.withColumn(\"concat_title\", concat_ws(' ', col(\"nostop_title\")))\n",
    "concatenated_cat = concatenated_title.withColumn(\"concat_cat\", concat_ws(' ', col(\"nostop_cat\")))\n",
    "concatenated_all = concatenated_cat.withColumn(\"concat_all\", concat_ws(' ', col('product_parent'), col('nostop_title'), col(\"nostop_cat\")))\n",
    "regexTokenizer = RegexTokenizer(inputCol='concat_all', outputCol=\"char\", pattern=\"\")\n",
    "split_words = regexTokenizer.transform(concatenated_all)\n",
    "\n",
    "# split_words.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGram(n=2, inputCol='char', outputCol=\"ngram\")\n",
    "ngram_split = ngrams.transform(split_words)\n",
    "\n",
    "# ngram_split.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing to create term freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='ngram', outputCol=\"vector\")\n",
    "hashed = hashingTF.transform(ngram_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minihash to generate LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = MinHashLSH(inputCol=\"vector\", outputCol=\"lsh\", numHashTables=3)\n",
    "model = mh.fit(hashed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.transform(hashed)\n",
    "# results_lens.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.approxSimilarityJoin(results, results, 0.05, distCol=\"JaccardDistance\")\\\n",
    "    .select(col(\"datasetA.product_id\").alias(\"idA\"),\n",
    "            col('datasetA.product_title').alias(\"productA\"),\n",
    "            col(\"datasetB.product_id\").alias(\"idB\"),\n",
    "            col(\"datasetB.product_title\").alias(\"productB\"),\n",
    "            col(\"JaccardDistance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
